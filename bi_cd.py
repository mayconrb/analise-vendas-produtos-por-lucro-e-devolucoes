# -*- coding: utf-8 -*-
"""BI-CD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XFSM_LBme9pKVGeCu5QFYYhHuuoWMXDm

# Regression Problem

## Imports
"""

# metrics
from sklearn.model_selection import train_test_split

import statsmodels.api as sm

# graphs
import matplotlib.pyplot as plt
import seaborn as sns

# data handler
import pandas as pd
import numpy as np

pd.set_option('display.max_column', None)

"""## Data Analysis

##### Loading dataset
"""

df = pd.read_excel('sample.xlsx')

df.head()

"""##### Checking NaN values"""

df.isna().sum()

"""##### Handle data"""

df_with_total_sales = df.copy()
df_with_total_sales['Total Sales'] = df['Sales'] * df['Quantity']

df_with_total_sales.head()

df_with_total_sales.describe()

df_with_total_sales.info()

"""##### Checking correlations"""

df_only_num = df_with_total_sales.select_dtypes(include=['float64'])

df_only_num.head()

correlations = df_only_num.corr()

sns.heatmap(
    data=correlations,
    annot=True,
    vmin=-1,
    vmax=1
)
plt.show()

sns.pairplot(
    data=df_only_num
)
plt.show()

"""##### Splitting variables"""

x, y = df_only_num[['Sales', 'Profit']], df_only_num.iloc[:,-1]

x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, shuffle=True, train_size=0.8)

"""##### Loading model"""

X = sm.add_constant(x)
model = sm.OLS(y, X).fit()

model.summary()

"""# Classification Problem

## Imports
"""

!pip install imblearn --user

# metrics
from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

# graphs
from imblearn.under_sampling import RandomUnderSampler

import matplotlib.pyplot as plt
import seaborn as sns

# data handler
import pandas as pd
import numpy as np

pd.set_option('display.max_column', None)

"""## Data Analysis

##### Laoding dataset
"""

df = pd.read_excel('sample.xlsx')

df.head()

"""##### Checking NaN values"""

df.isna().sum()

"""##### Data handle"""

df_label = df.groupby(by='Returned_1')

df_label['Category'].value_counts()

data = df_label['Category']

xlabel = data.unique()[0]
yaxis = data.value_counts()

sorted_yaxis_not_returned = [yaxis[0][keys] for keys in xlabel]
sorted_yaxis_returned = [yaxis[1][keys] for keys in xlabel]

fig, ax = plt.subplots(ncols=2, figsize=(12,5))

ax[0].set_title('Categories not returned')
ax[0].bar(xlabel, sorted_yaxis_not_returned)

ax[1].set_title('Categories returned')
ax[1].bar(xlabel, sorted_yaxis_returned)

plt.show()

data = df_label['Sub-Category']

xlabel = data.unique()[0]
yaxis = data.value_counts()

sorted_yaxis_not_returned = [yaxis[0][keys] for keys in xlabel]
sorted_yaxis_returned = [yaxis[1][keys] for keys in xlabel]

fig, ax = plt.subplots(ncols=2, figsize=(15,5))

ax[0].set_title('Sub-Category not returned')
ax[0].barh(xlabel, sorted_yaxis_not_returned)

ax[1].set_title('Sub-Category returned')
ax[1].barh(xlabel, sorted_yaxis_returned)

plt.show()

data = df_label['Quantity']

xlabel = data.unique()[0]
yaxis = data.value_counts()

sorted_yaxis_not_returned = [yaxis[0][keys] for keys in xlabel]
sorted_yaxis_returned = [yaxis[1][keys] for keys in xlabel]

fig, ax = plt.subplots(ncols=2, figsize=(12,5))

ax[0].set_title('Quantity not returned')
ax[0].bar(xlabel, sorted_yaxis_not_returned)

ax[1].set_title('Quantity returned')
ax[1].bar(xlabel, sorted_yaxis_returned)

plt.show()

"""##### Splitting dates"""

df.head()

df_splitted_date = df.copy()

df_splitted_date['Year-Order'] = df['Order Date'].map(lambda x: int(str(x).split('-')[0]))
df_splitted_date['Month-Order'] = df['Order Date'].map(lambda x: int(str(x).split('-')[1]))
df_splitted_date['Day-Order'] = df['Order Date'].map(lambda x: int(str(x).split('-')[2].split(' ')[0]))

df_splitted_date['Year-Ship'] = df['Ship Date'].map(lambda x: int(str(x).split('-')[0]))
df_splitted_date['Month-Ship'] = df['Ship Date'].map(lambda x: int(str(x).split('-')[1]))
df_splitted_date['Day-Ship'] = df['Ship Date'].map(lambda x: int(str(x).split('-')[2].split(' ')[0]))

df_splitted_date_gp = df_splitted_date.groupby(by='Returned_1')

df_splitted_date_gp.head()

data = df_splitted_date_gp['Month-Order']

xlabel = data.unique()[0]
yaxis = data.value_counts()

sorted_yaxis_not_returned = [yaxis[0][keys] for keys in xlabel]
sorted_yaxis_returned = [yaxis[1][keys] for keys in xlabel]

fig, ax = plt.subplots(ncols=2, figsize=(12,5))

ax[0].set_title('Month-Order not returned')
ax[0].bar(xlabel, sorted_yaxis_not_returned)

ax[1].set_title('Month-Order returned')
ax[1].bar(xlabel, sorted_yaxis_returned)

plt.show()

data = df_splitted_date_gp['Day-Order']

xlabel = data.unique()[0]
yaxis = data.value_counts()

sorted_yaxis_not_returned = [yaxis[0][keys] for keys in xlabel]
sorted_yaxis_returned = [yaxis[1][keys] for keys in xlabel]

fig, ax = plt.subplots(ncols=2, figsize=(12,5))

ax[0].set_title('Month-Order not returned')
ax[0].barh(xlabel, sorted_yaxis_not_returned)

ax[1].set_title('Month-Order returned')
ax[1].barh(xlabel, sorted_yaxis_returned)

plt.show()

"""##### Splitting data"""

main_data = df_splitted_date.select_dtypes(include=['float64', 'int64'])

main_data.head()

main_data.drop(labels=['Row ID', 'Postal Code'], axis=1, inplace=True)

main_data.head()

x, y = main_data.drop(labels='Returned_1', axis=1), main_data['Returned_1']

under_samp = RandomUnderSampler()
x,y = under_samp.fit_resample(x,y)

x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, shuffle=True, train_size=0.8)

best_acc = None
best_model = None
best_n = None

for n in range(1, 81):

    model = KNeighborsClassifier(n_neighbors=n)
    model.fit(x_train, y_train)

    pred = model.predict(x_test)

    acc = accuracy_score(y_test, pred)

    if best_acc is None or acc > best_acc:
        best_acc = acc
        best_model = model
        best_n = n
        cm = confusion_matrix(y_test, pred)

best_acc

cmd = ConfusionMatrixDisplay(cm)
cmd.plot()

